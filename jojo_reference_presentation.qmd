---
title: "Jojo_reference_presentation"
author: "Evi Jonas"
editor: visual
---

```{r load-packages}
#| label: load-pkgs
#| message: false
#| warning: false

# install.packages("RSelenium")
#install.packages("selenider")
#install.packages("chromote")
#install.packages("Rcrawler")
#install.packages("tidytext")
#install.packages("purrr")
#install.packages("glue")


library(tidyverse)
library(Rcrawler)
library(tidytext)
library(chromote)
library(stringr)
library(rvest)
library(readr)
library(purrr)
library(httr)
library(glue)
```

```{r}

# Define URLs for all episodes
urls <- c(
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96633",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96634",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96635",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96636",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96637",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96638",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96639",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96640",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96641",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96642",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96643",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96644",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96645",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96646",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96647",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96648",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96649",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96650",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96651",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96652",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96653",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96654",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96655",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96656",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96657",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96658",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96659",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96660",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96661",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96662",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96663",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96664",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96665",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96666",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96667",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96668",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96669",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96670",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96671",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96672",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96673",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96674",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96675",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96676",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96677",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96678",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96679",
  "https://transcripts.foreverdreaming.org/viewtopic.php?t=96680"
)

# Define a function to scrape episode text
scrape_episode <- function(url) {
  # Read the HTML content from the webpage
  episode_html <- read_html(url)
  
  # Extract the text content of the ".post-body" element
  episode_text <- html_text(html_nodes(episode_html, ".postbody"))
  
 # episode_text <- episode_text%>%
    #substr(episode_text, start = 907, stop = nchar(episode_text)) NOT NEEDED I THINK, SEEMS TO SCREW WITH IT
  
  # Remove any HTML tags and extra whitespace
  cleaned_episode <- gsub("<.*?>", "", episode_text)
  cleaned_episode <- trimws(cleaned_episode)
  
  # Remove "\n", "\n-", and "\t" occurrences
  cleaned_episode <- gsub("\n", "", cleaned_episode)
  cleaned_episode <- gsub("\n-", "", cleaned_episode)
  cleaned_episode <- gsub("\t", "", cleaned_episode)
  
  # Remove any extra whitespace
  cleaned_episode <- trimws(cleaned_episode)
  
  return(cleaned_episode)
}

# Define a list to store cleaned episode texts
all_episodes <- list()

# Scrape text for each episode
for (i in 1:length(urls)) {
  episode_text <- scrape_episode(urls[i])
  all_episodes[[i]] <- episode_text
}

# Now you have a list where each element contains the cleaned text for each episode


```

Turning all the episodes into a dataframe and remove stop words

```{r}
library(tidyverse)
library(tidytext)

data("stop_words")

# Combine all episodes into a single data frame
all_episodes_df <- map_dfr(all_episodes, ~ tibble(text = .x), .id = "episode")

# Tokenize the text
all_episodes_words <- all_episodes_df %>%
  unnest_tokens(output = word, input = text) 

#TRY TO REMOVE STOP WORDS
all_episodes_words <- all_episodes_words %>%
  anti_join(stop_words)
```

tokenize by word and plot most common words

```{r}
# Count the occurrences of each word
word_counts <- all_episodes_words %>%
  count(word, sort = TRUE)

# Filter words with counts greater than 1000
word_counts_filtered <- word_counts %>%
  filter(n > 100)

# Plot the word frequencies
word_counts_filtered %>%
  ggplot(aes(y = fct_reorder(word, n), x = n, fill = n)) +
  geom_col() +
  guides(fill = FALSE) +
  labs(y = "Word", x = "Frequency") +
  theme_minimal() +
  ggtitle("Most Frequent Words Across All Episodes (Occurrences > 100)")

```

SENTIMENT ANALYSIS

```{r}
all_episodes_words %>%
  inner_join(get_sentiments("bing"), by = "word") %>%
  count(sentiment, word, sort = TRUE) %>%
  group_by(sentiment) %>%
  slice_head(n = 20) %>%
  ggplot(aes(y = fct_reorder(word, n), x = n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free") +
  labs(
    title = "Sentiment and frequency of words across Stardust Crusaders",
    subtitle = "Bing lexicon",
    y = NULL, x = NULL
  ) +
  scale_fill_manual(values = c("positive" = "lightblue", "negative" = "lightcoral"))


```

SENTIMENT BY EPISODE

```{r}

library(tidyverse)
library(tidytext)

# Assuming all_episodes is a list of episode texts

# Combine all episodes into a single data frame
all_episodes_df <- map_dfr(all_episodes, ~ tibble(text = .x), .id = "episode")

# Tokenize the text
all_episodes_words <- all_episodes_df %>%
  unnest_tokens(output = word, input = text) 

# Get sentiments of words using the "bing" lexicon
all_episodes_sentiments <- all_episodes_words %>%
  inner_join(get_sentiments("bing"), by = "word") %>%
  select(episode, sentiment)

# Count the occurrences of each sentiment by episode
sentiment_counts <- all_episodes_sentiments %>%
  count(episode, sentiment)

# Plot the sentiment counts by episode
ggplot(sentiment_counts, aes(x = episode, y = n, fill = sentiment)) +
  geom_bar(stat = "identity", position = "stack") +
  labs(title = "Sentiment by Episode",
       x = "Episode",
       y = "Count",
       fill = "Sentiment") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability


#it seems to vary somewhat regularly. does this indicate that there is a regular cycle in mood built into the pacing of the show??
```

LOOKING AT BIGRAM FREQUENCY

```{r}
# Load the dplyr package
library(dplyr)

threshold <- 20

# Tokenize the text
all_episodes_bigrams <- all_episodes_df %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
  mutate(i = row_number()) %>%    # add index for later grouping
  unnest_tokens(word, bigram, drop = FALSE) %>%    # tokenize bigrams into words
  anti_join(stop_words) %>%    # drop rows with stop words
  group_by(i) %>%    # group by bigram index
  filter(n() == 2) %>%    # drop bigram instances where only one word left
  summarise(bigram = unique(bigram), .groups = "drop")

all_episodes_bigrams %>%
  mutate(
    bigram = if_else(bigram == "care home", "care home(s)", bigram),
    bigram = if_else(bigram == "care homes", "care home(s)", bigram)
  ) %>%
  count(bigram, sort = TRUE) %>%
  filter(n > threshold) %>%
  ggplot(aes(y = fct_reorder(bigram, n), x = n, fill = n)) +
  geom_col() +
  guides(fill = FALSE) +
  labs(
    title = "Frequency of bigrams Stardust Crusaders",
    subtitle = glue("Bigrams occurring more than {threshold} times"),
    y = NULL, x = NULL
  )

```

THIS IS THE COMMAND TO PROCESS JUST THIS FILE NOT THE PROPOSAL

```{R}
#To use the terminal within RStudio, you can go to "Tools" -> "Terminal" -> "New Terminal". Then you can navigate to the directory where your project files are located and run the command there.
#quarto preview jojo_reference_presentation.qmd --to html --no-watch-inputs --no-browse

rmarkdown::render("jojo_reference_presentation.qmd")
```
