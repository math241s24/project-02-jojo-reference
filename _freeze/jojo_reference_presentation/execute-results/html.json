{
  "hash": "57ee2a0753b71a126914520d0dc304b5",
  "result": {
    "markdown": "---\ntitle: \"Jojo_reference_presentation\"\nauthor: \"Evi Jonas\"\neditor: visual\n---\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"RSelenium\")\n#install.packages(\"selenider\")\n#install.packages(\"chromote\")\n#install.packages(\"selenium\")\n#install.packages(\"Rcrawler\")\n#install.packages(\"tidytext\")\n#install.packages(\"purrr\")\n#install.packages(\"glue\")\n\n\nlibrary(tidyverse)\nlibrary(RSelenium)\nlibrary(selenider)\nlibrary(selenium)\nlibrary(Rcrawler)\nlibrary(tidytext)\nlibrary(chromote)\nlibrary(stringr)\nlibrary(rvest)\nlibrary(readr)\nlibrary(purrr)\nlibrary(httr)\nlibrary(glue)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define URLs for all episodes\nurls <- c(\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96633\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96634\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96635\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96636\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96637\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96638\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96639\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96640\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96641\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96642\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96643\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96644\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96645\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96646\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96647\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96648\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96649\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96650\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96651\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96652\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96653\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96654\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96655\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96656\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96657\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96658\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96659\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96660\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96661\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96662\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96663\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96664\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96665\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96666\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96667\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96668\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96669\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96670\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96671\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96672\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96673\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96674\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96675\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96676\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96677\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96678\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96679\",\n  \"https://transcripts.foreverdreaming.org/viewtopic.php?t=96680\"\n)\n\n# Define a function to scrape episode text\nscrape_episode <- function(url) {\n  # Read the HTML content from the webpage\n  episode_html <- read_html(url)\n  \n  # Extract the text content of the \"page-body\" element\n  episode_text <- html_text(html_nodes(episode_html, \".postbody\"))\n  \n # episode_text <- episode_text%>%\n    #substr(episode_text, start = 907, stop = nchar(episode_text)) NOT NEEDED I THINK, SEEMS TO SCREW WITH IT\n  \n  # Remove any HTML tags and extra whitespace\n  cleaned_episode <- gsub(\"<.*?>\", \"\", episode_text)\n  cleaned_episode <- trimws(cleaned_episode)\n  \n  # Remove \"\\n\", \"\\n-\", and \"\\t\" occurrences\n  cleaned_episode <- gsub(\"\\n\", \"\", cleaned_episode)\n  cleaned_episode <- gsub(\"\\n-\", \"\", cleaned_episode)\n  cleaned_episode <- gsub(\"\\t\", \"\", cleaned_episode)\n  \n  # Remove any extra whitespace\n  cleaned_episode <- trimws(cleaned_episode)\n  \n  return(cleaned_episode)\n}\n\n# Define a list to store cleaned episode texts\nall_episodes <- list()\n\n# Scrape text for each episode\nfor (i in 1:length(urls)) {\n  episode_text <- scrape_episode(urls[i])\n  all_episodes[[i]] <- episode_text\n}\n\n# Now you have a list where each element contains the cleaned text for each episode\n```\n:::\n\n\nTurning all the episodes into a dataframe and remove stop words\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidytext)\n\ndata(\"stop_words\")\n\n# Combine all episodes into a single data frame\nall_episodes_df <- map_dfr(all_episodes, ~ tibble(text = .x), .id = \"episode\")\n\n# Tokenize the text\nall_episodes_words <- all_episodes_df %>%\n  unnest_tokens(output = word, input = text) \n\n#TRY TO REMOVE STOP WORDS\nall_episodes_words <- all_episodes_words %>%\n  anti_join(stop_words)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(word)`\n```\n:::\n:::\n\n\ntokenize by word and plot most common words\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Count the occurrences of each word\nword_counts <- all_episodes_words %>%\n  count(word, sort = TRUE)\n\n# Filter words with counts greater than 1000\nword_counts_filtered <- word_counts %>%\n  filter(n > 100)\n\n# Plot the word frequencies\nword_counts_filtered %>%\n  ggplot(aes(y = fct_reorder(word, n), x = n, fill = n)) +\n  geom_col() +\n  guides(fill = FALSE) +\n  labs(y = \"Word\", x = \"Frequency\") +\n  theme_minimal() +\n  ggtitle(\"Most Frequent Words Across All Episodes (Occurrences > 100)\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n```\n:::\n\n::: {.cell-output-display}\n![](jojo_reference_presentation_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\nSENTIMENT ANALYSIS\n\n\n::: {.cell}\n\n```{.r .cell-code}\nall_episodes_words %>%\n  inner_join(get_sentiments(\"bing\"), by = \"word\") %>%\n  count(sentiment, word, sort = TRUE) %>%\n  group_by(sentiment) %>%\n  slice_head(n = 20) %>%\n  ggplot(aes(y = fct_reorder(word, n), x = n, fill = sentiment)) +\n  geom_col(show.legend = FALSE) +\n  facet_wrap(~sentiment, scales = \"free\") +\n  labs(\n    title = \"Sentiment and frequency of words across Stardust Crusaders\",\n    subtitle = \"Bing lexicon\",\n    y = NULL, x = NULL\n  ) +\n  scale_fill_manual(values = c(\"positive\" = \"lightblue\", \"negative\" = \"lightcoral\"))\n```\n\n::: {.cell-output-display}\n![](jojo_reference_presentation_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\nSENTIMENT BY EPISODE\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidytext)\n\n# Assuming all_episodes is a list of episode texts\n\n# Combine all episodes into a single data frame\nall_episodes_df <- map_dfr(all_episodes, ~ tibble(text = .x), .id = \"episode\")\n\n# Tokenize the text\nall_episodes_words <- all_episodes_df %>%\n  unnest_tokens(output = word, input = text) \n\n# Get sentiments of words using the \"bing\" lexicon\nall_episodes_sentiments <- all_episodes_words %>%\n  inner_join(get_sentiments(\"bing\"), by = \"word\") %>%\n  select(episode, sentiment)\n\n# Count the occurrences of each sentiment by episode\nsentiment_counts <- all_episodes_sentiments %>%\n  count(episode, sentiment)\n\n# Plot the sentiment counts by episode\nggplot(sentiment_counts, aes(x = episode, y = n, fill = sentiment)) +\n  geom_bar(stat = \"identity\", position = \"stack\") +\n  labs(title = \"Sentiment by Episode\",\n       x = \"Episode\",\n       y = \"Count\",\n       fill = \"Sentiment\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))  # Rotate x-axis labels for better readability\n```\n\n::: {.cell-output-display}\n![](jojo_reference_presentation_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#it seems to vary somewhat regularly. does this indicate that there is a regular cycle in mood built into the pacing of the show??\n```\n:::\n\n\nLOOKING AT BIGRAM FREQUENCY\n\n\n::: {.cell}\n\n```{.r .cell-code}\nthreshold <- 75\n\n# Tokenize the text\nall_episodes_bigrams <- all_episodes_df %>%\n  unnest_tokens(bigram, text, token = \"ngrams\", n = 2) %>%\n  mutate(i = row_number()) %>%    # add index for later grouping\n  unnest_tokens(word, bigram, drop = FALSE) %>%    # tokenize bigrams into words\n  anti_join(stop_words) %>%    # drop rows with stop words\n  group_by(i) %>%    # group by bigram index\n  filter(n() == 2) %>%    # drop bigram instances where only one word left\n  summarise(bigram = unique(bigram), .groups = \"drop\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nJoining with `by = join_by(word)`\n```\n:::\n\n```{.r .cell-code}\nall_episodes_bigrams %>%\n  mutate(\n    bigram = if_else(bigram == \"care home\", \"care home(s)\", bigram),\n    bigram = if_else(bigram == \"care homes\", \"care home(s)\", bigram)\n  ) %>%\n  count(bigram, sort = TRUE) %>%\n  filter(n > threshold) %>%\n  ggplot(aes(y = fct_reorder(bigram, n), x = n, fill = n)) +\n  geom_col() +\n  guides(fill = FALSE) +\n  labs(\n    title = \"Frequency of bigrams Stardust Crusaders\",\n    subtitle = glue(\"Bigrams occurring more than {threshold} times\"),\n    y = NULL, x = NULL\n  )\n```\n\n::: {.cell-output-display}\n![](jojo_reference_presentation_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "jojo_reference_presentation_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}